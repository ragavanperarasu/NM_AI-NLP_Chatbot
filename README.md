ðŸ¤– AI Chatbot using DeepSeek R1 (1.5B) with RAG

This project is an AI-powered chatbot application using the **DeepSeek R1 1.5B model** with **Retrieval-Augmented Generation (RAG)**. It allows users to chat with a locally hosted LLM, with support for custom knowledge base retrieval using **MongoDB** and a clean **React Native** frontend. The backend is built using **Node.js** and **Express.js**.

âœ¨ Features

- ðŸ” **RAG-based Chatbot**: Combines a lightweight LLM with MongoDB vector search for relevant document retrieval.
- ðŸ§  **DeepSeek R1 (1.5B)** model: Efficient and lightweight LLM run locally via [Ollama](https://ollama.com).
- ðŸ’¬ **Real-time Chat UI**: Built with React Native and React Native Paper.
- ðŸ“¦ **Node.js Backend**: Handles chat logic, vector embeddings, and communication with MongoDB.
- ðŸ—ƒï¸ **MongoDB Vector Store**: Stores knowledge base documents with embedded vectors for RAG.
- ðŸ“± **Cross-platform mobile app** using React Native.


ðŸ—ï¸ Architecture


User (React Native App)
       |
       v
Node.js Server (Express.js)
       |
       |---> MongoDB (Vector DB for RAG)
       |
       |---> Ollama (DeepSeek R1 model for response generation)


ðŸ“ Folder Structure


root/
â”œâ”€â”€ backend/         # Node.js + Express + MongoDB + RAG logic
â”‚   â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ controllers/
â”‚   â””â”€â”€ index.js
â”œâ”€â”€ frontend/        # React Native app
â”‚   â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ screens/
â”‚   â””â”€â”€ App.js
â”œâ”€â”€ docs/            # Sample documents for RAG
â””â”€â”€ README.md



ðŸš€ Getting Started

1. Clone the Repo


git clone https://github.com/yourusername/your-chatbot-project.git
cd your-chatbot-project


2. Setup the Backend

Install Dependencies


cd backend
npm install


Start MongoDB

Make sure MongoDB is running. If using MongoDB Atlas, set the connection string in `.env`.

env
MONGO_URI=mongodb://localhost:27017/chatbotDB


Start Ollama with DeepSeek R1


ollama run deepseek-coder:1.5b

Run Backend

```bash
node index.js
```

---

3. Setup the Frontend

Install Dependencies

```bash
cd ../frontend
npm install
```

Run React Native App

```bash
npx react-native run-android # or run-ios
```


ðŸ§  RAG Pipeline (How it Works)

1. **User sends a query** via chat.
2. **Server searches MongoDB** using vector similarity to retrieve relevant documents.
3. Retrieved context is **combined with the user query**.
4. Combined input is sent to the **DeepSeek R1 model** via Ollama.
5. **Model generates a response** and sends it back to the app.


ðŸ“š Add Custom Knowledge Base

Add your documents in `docs/` folder and use the embedding script (in `backend/rag/embed.js`) to store vectors in MongoDB.


ðŸ”§ Technologies Used

- **Frontend**: React Native, React Native Paper
- **Backend**: Node.js, Express.js
- **Database**: MongoDB (Vector Search)
- **LLM**: DeepSeek R1 1.5B via Ollama
- **Embedding**: `ollama.embeddings` API or compatible tool


ðŸ“ Future Improvements

- ðŸ”” Push notifications
- ðŸŒ Web version with React.js
- ðŸ—‚ï¸ Admin dashboard to manage documents
- ðŸ§ª Test coverage for RAG logic


ðŸ“¸ Screenshots

> _Coming soon..._


ðŸ’¡ Contributing

Pull requests are welcome. For major changes, please open an issue first.


ðŸ“œ License

[MIT License](LICENSE)
